# 02. Hypothesis Testing

## M·ª•c Ti√™u
- Hi·ªÉu ƒë∆∞·ª£c kh√°i ni·ªám hypothesis testing v√† khi n√†o s·ª≠ d·ª•ng
- N·∫Øm v·ªØng c√°c lo·∫°i test ph·ªï bi·∫øn: t-test, chi-square, ANOVA
- Bi·∫øt c√°ch interpret p-value v√† significance level
- √Åp d·ª•ng v√†o c√°c t√¨nh hu·ªëng th·ª±c t·∫ø: A/B testing, so s√°nh nh√≥m

## Hypothesis Testing L√† G√¨?

**Hypothesis testing (ki·ªÉm ƒë·ªãnh gi·∫£ thuy·∫øt)** l√† ph∆∞∆°ng ph√°p th·ªëng k√™ ƒë·ªÉ:
- **Ra quy·∫øt ƒë·ªãnh** d·ª±a tr√™n d·ªØ li·ªáu
- **Ki·ªÉm tra** xem m·ªôt claim c√≥ ƒë√∫ng kh√¥ng
- **So s√°nh** c√°c nh√≥m v·ªõi nhau

**V√≠ d·ª• th·ª±c t·∫ø**:
- "Campaign m·ªõi c√≥ tƒÉng conversion rate kh√¥ng?"
- "S·∫£n ph·∫©m A c√≥ t·ªët h∆°n s·∫£n ph·∫©m B kh√¥ng?"
- "Gi√° m·ªõi c√≥ ·∫£nh h∆∞·ªüng ƒë·∫øn doanh s·ªë kh√¥ng?"

## C√°c Kh√°i Ni·ªám C∆° B·∫£n

### Null Hypothesis (H0) v√† Alternative Hypothesis (H1)

- **H0 (Null Hypothesis)**: Gi·∫£ thuy·∫øt m·∫∑c ƒë·ªãnh, th∆∞·ªùng l√† "kh√¥ng c√≥ s·ª± kh√°c bi·ªát"
- **H1 (Alternative Hypothesis)**: Gi·∫£ thuy·∫øt b·∫°n mu·ªën ch·ª©ng minh

**V√≠ d·ª• ƒë∆°n gi·∫£n**:
- **H0**: Mean doanh s·ªë = 50,000,000 VND
- **H1**: Mean doanh s·ªë ‚â† 50,000,000 VND

```python
from scipy import stats
import numpy as np
import pandas as pd

# V√≠ d·ª• ƒë∆°n gi·∫£n
# H0: Mean = 50,000,000
# H1: Mean ‚â† 50,000,000
sample = np.random.normal(52_000_000, 10_000_000, 100)
t_stat, p_value = stats.ttest_1samp(sample, 50_000_000)

print(f"T-statistic: {t_stat:.3f}")
print(f"P-value: {p_value:.4f}")
if p_value < 0.05:
    print("‚Üí B√°c b·ªè H0: Mean kh√°c 50,000,000")
else:
    print("‚Üí Kh√¥ng ƒë·ªß b·∫±ng ch·ª©ng b√°c b·ªè H0")
```

### P-value (Gi√° Tr·ªã P)

**P-value** l√† x√°c su·∫•t quan s√°t ƒë∆∞·ª£c k·∫øt qu·∫£ nh∆∞ v·∫≠y (ho·∫∑c c·ª±c ƒëoan h∆°n) n·∫øu H0 ƒë√∫ng.

**C√°ch hi·ªÉu**:
- **P-value < 0.05**: C√≥ b·∫±ng ch·ª©ng m·∫°nh ƒë·ªÉ b√°c b·ªè H0 ‚Üí K·∫øt qu·∫£ c√≥ √Ω nghƒ©a th·ªëng k√™
- **P-value >= 0.05**: Kh√¥ng ƒë·ªß b·∫±ng ch·ª©ng ƒë·ªÉ b√°c b·ªè H0 ‚Üí K·∫øt qu·∫£ kh√¥ng c√≥ √Ω nghƒ©a th·ªëng k√™

**L∆∞u √Ω quan tr·ªçng**:
- P-value < 0.05 **KH√îNG** c√≥ nghƒ©a l√† "H1 ƒë√∫ng 95%"
- P-value < 0.05 c√≥ nghƒ©a l√† "n·∫øu H0 ƒë√∫ng, x√°c su·∫•t quan s√°t ƒë∆∞·ª£c k·∫øt qu·∫£ n√†y < 5%"

### Significance Level (Œ± - Alpha)

**Significance level (m·ª©c √Ω nghƒ©a)** l√† ng∆∞·ª°ng b·∫°n ch·ªçn ƒë·ªÉ quy·∫øt ƒë·ªãnh b√°c b·ªè H0.

- **Œ± = 0.05** (5%): Ph·ªï bi·∫øn nh·∫•t
- **Œ± = 0.01** (1%): Nghi√™m ng·∫∑t h∆°n
- **Œ± = 0.10** (10%): √çt nghi√™m ng·∫∑t h∆°n

**Quy t·∫Øc**:
- N·∫øu **p-value < Œ±**: B√°c b·ªè H0
- N·∫øu **p-value >= Œ±**: Kh√¥ng b√°c b·ªè H0

### Type I v√† Type II Errors

**Type I Error (L·ªói Lo·∫°i I)**: B√°c b·ªè H0 khi H0 ƒë√∫ng
- X√°c su·∫•t = Œ± (significance level)
- V√≠ d·ª•: K·∫øt lu·∫≠n campaign c√≥ hi·ªáu qu·∫£ khi th·ª±c ra kh√¥ng

**Type II Error (L·ªói Lo·∫°i II)**: Kh√¥ng b√°c b·ªè H0 khi H0 sai
- X√°c su·∫•t = Œ≤
- V√≠ d·ª•: K·∫øt lu·∫≠n campaign kh√¥ng hi·ªáu qu·∫£ khi th·ª±c ra c√≥

**Power of a Test (L·ª±c Ki·ªÉm ƒê·ªãnh)**: 1 - Œ≤
- X√°c su·∫•t b√°c b·ªè H0 khi H0 th·ª±c s·ª± sai
- Power cao = D·ªÖ ph√°t hi·ªán s·ª± kh√°c bi·ªát th·ª±c s·ª±

## C√°c Lo·∫°i Test Ph·ªï Bi·∫øn

### 1. One-Sample T-Test

**M·ª•c ƒë√≠ch**: So s√°nh mean c·ªßa m·ªôt sample v·ªõi m·ªôt gi√° tr·ªã c·ª• th·ªÉ

**V√≠ d·ª•**: Doanh s·ªë trung b√¨nh c√≥ b·∫±ng 50 tri·ªáu kh√¥ng?

```python
from scipy import stats
import numpy as np

# D·ªØ li·ªáu doanh s·ªë (tri·ªáu VND)
sales = np.array([45, 52, 48, 55, 50, 53, 49, 51, 47, 54])

# H0: Mean = 50
# H1: Mean ‚â† 50
t_stat, p_value = stats.ttest_1samp(sales, 50)

print(f"T-statistic: {t_stat:.3f}")
print(f"P-value: {p_value:.4f}")
print(f"Mean: {sales.mean():.2f}")

if p_value < 0.05:
    print("‚Üí B√°c b·ªè H0: Mean kh√°c 50 tri·ªáu VND")
else:
    print("‚Üí Kh√¥ng ƒë·ªß b·∫±ng ch·ª©ng: Mean c√≥ th·ªÉ b·∫±ng 50 tri·ªáu VND")
```

### 2. Two-Sample T-Test

**M·ª•c ƒë√≠ch**: So s√°nh mean c·ªßa 2 nh√≥m ƒë·ªôc l·∫≠p

**V√≠ d·ª•**: Conversion rate c·ªßa campaign A c√≥ kh√°c campaign B kh√¥ng?

```python
import pandas as pd
import numpy as np
from scipy import stats

# D·ªØ li·ªáu A/B test
np.random.seed(42)
campaign_a = np.random.normal(0.03, 0.01, 1000)  # Conversion rate 3%
campaign_b = np.random.normal(0.035, 0.01, 1000)  # Conversion rate 3.5%

# H0: Mean A = Mean B
# H1: Mean A ‚â† Mean B
t_stat, p_value = stats.ttest_ind(campaign_a, campaign_b)

print("=== A/B TEST RESULTS ===")
print(f"Campaign A - Mean: {campaign_a.mean():.4f}, Std: {campaign_a.std():.4f}")
print(f"Campaign B - Mean: {campaign_b.mean():.4f}, Std: {campaign_b.std():.4f}")
print(f"\nT-statistic: {t_stat:.3f}")
print(f"P-value: {p_value:.4f}")

if p_value < 0.05:
    print("\n‚Üí B√°c b·ªè H0: Campaign B c√≥ conversion rate cao h∆°n ƒë√°ng k·ªÉ")
    improvement = ((campaign_b.mean() - campaign_a.mean()) / campaign_a.mean()) * 100
    print(f"‚Üí C·∫£i thi·ªán: {improvement:.1f}%")
else:
    print("\n‚Üí Kh√¥ng c√≥ s·ª± kh√°c bi·ªát ƒë√°ng k·ªÉ gi·ªØa 2 campaigns")
```

### 3. Paired T-Test

**M·ª•c ƒë√≠ch**: So s√°nh mean c·ªßa 2 nh√≥m c√≥ li√™n quan (tr∆∞·ªõc/sau, c√πng ƒë·ªëi t∆∞·ª£ng)

**V√≠ d·ª•**: Doanh s·ªë tr∆∞·ªõc v√† sau campaign c√≥ kh√°c nhau kh√¥ng?

```python
# D·ªØ li·ªáu tr∆∞·ªõc v√† sau campaign (c√πng stores)
before = np.array([100, 105, 98, 102, 110, 95, 108, 103, 97, 104])
after = np.array([115, 120, 112, 118, 125, 110, 122, 117, 111, 119])

# H0: Mean difference = 0
# H1: Mean difference ‚â† 0
t_stat, p_value = stats.ttest_rel(after, before)

print("=== BEFORE-AFTER ANALYSIS ===")
print(f"Before - Mean: {before.mean():.2f}")
print(f"After - Mean: {after.mean():.2f}")
print(f"Difference: {after.mean() - before.mean():.2f}")
print(f"\nT-statistic: {t_stat:.3f}")
print(f"P-value: {p_value:.4f}")

if p_value < 0.05:
    improvement = ((after.mean() - before.mean()) / before.mean()) * 100
    print(f"\n‚Üí Campaign c√≥ hi·ªáu qu·∫£: TƒÉng {improvement:.1f}%")
else:
    print("\n‚Üí Campaign kh√¥ng c√≥ hi·ªáu qu·∫£ ƒë√°ng k·ªÉ")
```

### 4. Chi-Square Test

**M·ª•c ƒë√≠ch**: Ki·ªÉm tra m·ªëi quan h·ªá gi·ªØa 2 bi·∫øn categorical

**V√≠ d·ª•**: Ngu·ªìn traffic c√≥ li√™n quan ƒë·∫øn conversion kh√¥ng?

```python
from scipy.stats import chi2_contingency
import pandas as pd
import numpy as np

# D·ªØ li·ªáu: Traffic source vs Conversion
np.random.seed(42)
data = {
    'source': ['Google', 'Facebook', 'Email', 'Direct'] * 250,
    'converted': np.random.choice([True, False], 1000, p=[0.03, 0.97])
}

df = pd.DataFrame(data)

# T·∫°o contingency table
contingency = pd.crosstab(df['source'], df['converted'])
print("=== CONTINGENCY TABLE ===")
print(contingency)

# Chi-square test
chi2, p_value, dof, expected = chi2_contingency(contingency)

print(f"\nChi-square statistic: {chi2:.3f}")
print(f"P-value: {p_value:.4f}")
print(f"Degrees of freedom: {dof}")

if p_value < 0.05:
    print("\n‚Üí C√≥ m·ªëi quan h·ªá gi·ªØa source v√† conversion")
    # Ph√¢n t√≠ch chi ti·∫øt
    conversion_by_source = df.groupby('source')['converted'].mean()
    print("\nConversion rate by source:")
    print(conversion_by_source.sort_values(ascending=False))
else:
    print("\n‚Üí Kh√¥ng c√≥ m·ªëi quan h·ªá gi·ªØa source v√† conversion")
```

### 5. ANOVA (Analysis of Variance)

**M·ª•c ƒë√≠ch**: So s√°nh mean c·ªßa 3+ nh√≥m

**V√≠ d·ª•**: Doanh s·ªë c√≥ kh√°c nhau gi·ªØa c√°c regions kh√¥ng?

```python
from scipy.stats import f_oneway
import numpy as np

# D·ªØ li·ªáu doanh s·ªë theo region
np.random.seed(42)
north = np.random.normal(100, 10, 50)
central = np.random.normal(105, 12, 50)
south = np.random.normal(98, 11, 50)

# H0: T·∫•t c·∫£ means b·∫±ng nhau
# H1: √çt nh·∫•t m·ªôt mean kh√°c
f_stat, p_value = f_oneway(north, central, south)

print("=== ANOVA TEST ===")
print(f"North - Mean: {north.mean():.2f}, Std: {north.std():.2f}")
print(f"Central - Mean: {central.mean():.2f}, Std: {central.std():.2f}")
print(f"South - Mean: {south.mean():.2f}, Std: {south.std():.2f}")
print(f"\nF-statistic: {f_stat:.3f}")
print(f"P-value: {p_value:.4f}")

if p_value < 0.05:
    print("\n‚Üí C√≥ s·ª± kh√°c bi·ªát ƒë√°ng k·ªÉ gi·ªØa c√°c regions")
    # Post-hoc test ƒë·ªÉ xem region n√†o kh√°c
    from scipy.stats import ttest_ind
    print("\nPairwise comparisons:")
    t_stat_nc, p_nc = ttest_ind(north, central)
    t_stat_ns, p_ns = ttest_ind(north, south)
    t_stat_cs, p_cs = ttest_ind(central, south)
    print(f"North vs Central: p-value = {p_nc:.4f}")
    print(f"North vs South: p-value = {p_ns:.4f}")
    print(f"Central vs South: p-value = {p_cs:.4f}")
else:
    print("\n‚Üí Kh√¥ng c√≥ s·ª± kh√°c bi·ªát ƒë√°ng k·ªÉ gi·ªØa c√°c regions")
```

## A/B Testing Th·ª±c T·∫ø

### Case Study: Test Landing Page M·ªõi

```python
import pandas as pd
import numpy as np
from scipy import stats

# D·ªØ li·ªáu A/B test: Landing page c≈© vs m·ªõi
np.random.seed(42)
n_visitors = 5000

# Control group (landing page c≈©)
control = pd.DataFrame({
    'visitor_id': range(1, n_visitors + 1),
    'group': 'control',
    'converted': np.random.choice([True, False], n_visitors, p=[0.025, 0.975]),
    'time_on_page': np.random.normal(45, 15, n_visitors)
})

# Treatment group (landing page m·ªõi)
treatment = pd.DataFrame({
    'visitor_id': range(n_visitors + 1, 2 * n_visitors + 1),
    'group': 'treatment',
    'converted': np.random.choice([True, False], n_visitors, p=[0.032, 0.968]),
    'time_on_page': np.random.normal(55, 18, n_visitors)
})

test_data = pd.concat([control, treatment], ignore_index=True)

# Ph√¢n t√≠ch conversion rate
conversion_summary = test_data.groupby('group').agg({
    'converted': ['mean', 'sum', 'count']
}).round(4)
conversion_summary.columns = ['conversion_rate', 'conversions', 'visitors']

print("=== CONVERSION RATE SUMMARY ===")
print(conversion_summary)

# Statistical test
control_converted = control['converted']
treatment_converted = treatment['converted']

# Chi-square test (ho·∫∑c two-proportion z-test)
from scipy.stats import chi2_contingency
contingency = pd.crosstab(test_data['group'], test_data['converted'])
chi2, p_value, dof, expected = chi2_contingency(contingency)

print(f"\nChi-square test:")
print(f"  Chi-square: {chi2:.3f}")
print(f"  P-value: {p_value:.4f}")

# T√≠nh improvement
control_rate = control_converted.mean()
treatment_rate = treatment_converted.mean()
improvement = ((treatment_rate - control_rate) / control_rate) * 100

print(f"\n=== CONCLUSION ===")
if p_value < 0.05:
    print(f"‚úì Landing page m·ªõi c√≥ conversion rate cao h∆°n ƒë√°ng k·ªÉ")
    print(f"  Improvement: {improvement:.1f}%")
    print(f"  Control: {control_rate*100:.2f}%")
    print(f"  Treatment: {treatment_rate*100:.2f}%")
    print(f"\n‚Üí Recommendation: Tri·ªÉn khai landing page m·ªõi")
else:
    print(f"‚úó Kh√¥ng c√≥ s·ª± kh√°c bi·ªát ƒë√°ng k·ªÉ")
    print(f"  Control: {control_rate*100:.2f}%")
    print(f"  Treatment: {treatment_rate*100:.2f}%")
    print(f"\n‚Üí Recommendation: C·∫ßn test th√™m ho·∫∑c gi·ªØ nguy√™n")
```

## ƒêi·ªÅu Ki·ªán S·ª≠ D·ª•ng C√°c Test

### T-Test
- D·ªØ li·ªáu **numeric**
- Ph√¢n b·ªë **g·∫ßn nh∆∞ normal** (ho·∫∑c sample size l·ªõn)
- **Independent samples** (v·ªõi two-sample t-test)

### Chi-Square Test
- D·ªØ li·ªáu **categorical**
- **Expected frequency >= 5** trong m·ªói cell

### ANOVA
- D·ªØ li·ªáu **numeric**
- Ph√¢n b·ªë **g·∫ßn nh∆∞ normal**
- **Variance b·∫±ng nhau** gi·ªØa c√°c nh√≥m (homogeneity of variance)

## Best Practices

1. **Ki·ªÉm tra assumptions tr∆∞·ªõc**: Normal distribution, equal variance, etc.
2. **Ch·ªçn test ph√π h·ª£p**: D·ª±a tr√™n lo·∫°i d·ªØ li·ªáu v√† c√¢u h·ªèi
3. **Interpret k·∫øt qu·∫£ ƒë√∫ng**: P-value < 0.05 kh√¥ng c√≥ nghƒ©a l√† "hi·ªáu qu·∫£ 95%"
4. **Consider effect size**: Kh√¥ng ch·ªâ p-value, m√† c√≤n ƒë·ªô l·ªõn c·ªßa s·ª± kh√°c bi·ªát
5. **Multiple testing correction**: N·∫øu test nhi·ªÅu l·∫ßn, c·∫ßn ƒëi·ªÅu ch·ªânh Œ±

## üìù B√†i T·∫≠p Th·ª±c H√†nh

### B√†i T·∫≠p 1: A/B Test Analysis
Ph√¢n t√≠ch A/B test v·ªõi d·ªØ li·ªáu conversion rate v√† ƒë∆∞a ra k·∫øt lu·∫≠n.

### B√†i T·∫≠p 2: Before-After Analysis
So s√°nh doanh s·ªë tr∆∞·ªõc v√† sau campaign s·ª≠ d·ª•ng paired t-test.

### B√†i T·∫≠p 3: Multi-Group Comparison
So s√°nh performance c·ªßa 4 s·∫£n ph·∫©m kh√°c nhau s·ª≠ d·ª•ng ANOVA.

---

**L∆∞u √Ω**: Hypothesis testing l√† c√¥ng c·ª• m·∫°nh m·∫Ω, nh∆∞ng c·∫ßn hi·ªÉu ƒë√∫ng v√† s·ª≠ d·ª•ng ƒë√∫ng c√°ch. Lu√¥n k·∫øt h·ª£p v·ªõi domain knowledge v√† business context.

